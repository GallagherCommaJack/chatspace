{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma2-27B Attention Analysis\n",
    "\n",
    "This notebook analyzes how instruction tuning modifies attention patterns for PC and semantic vectors.\n",
    "\n",
    "**Key Analyses:**\n",
    "1. **QK Affinity**: Raw attention logits (before softmax) reveal semantic affinities\n",
    "2. **VO Decomposition**: What semantic content flows through when attending to a vector\n",
    "3. **Base vs Instruct Comparison**: How instruction tuning changes routing\n",
    "\n",
    "**Approach:**\n",
    "- Compute QK affinity matrices for PC and semantic vectors\n",
    "- Compute VO decomposition (value-output transformation)\n",
    "- Analyze z-scores relative to random baseline\n",
    "- Identify layers and patterns where instruction tuning has strongest effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "from collections import OrderedDict\n",
    "\n",
    "from chatspace.analysis import (\n",
    "    load_pca_data,\n",
    "    extract_pc_components,\n",
    "    load_individual_role_vectors,\n",
    "    load_individual_trait_vectors,\n",
    "    normalize_vector,\n",
    "    compute_qk_affinity_matrix,\n",
    "    compute_vo_decomposition,\n",
    "    compute_z_score_matrices,\n",
    "    get_top_interactions,\n",
    "    analyze_pc_pattern\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models and Prepare Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b1d2a2c0094b58b570a67b01a825c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aeeb5d95394661ba2dcdca9c225aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Models loaded\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "base_model_id = \"google/gemma-2-27b\"\n",
    "instruct_model_id = \"google/gemma-2-27b-it\"\n",
    "\n",
    "print(\"Loading models...\")\n",
    "config = AutoConfig.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=torch.bfloat16, device_map=\"cpu\")\n",
    "instruct_model = AutoModelForCausalLM.from_pretrained(instruct_model_id, torch_dtype=torch.bfloat16, device_map=\"cpu\")\n",
    "print(\"\u2713 Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-pcs",
   "metadata": {},
   "outputs": [],
   "source": "# Load PCA data and extract all PCs we'll analyze\npersona_data_root = Path(\"/workspace/persona-data\")\nroles_pca_dir = persona_data_root / \"gemma-2-27b\" / \"roles_240\" / \"pca\"\ntraits_pca_dir = persona_data_root / \"gemma-2-27b\" / \"traits_240\" / \"pca\"\n\npca_data, _ = load_pca_data(roles_pca_dir)\npca_layer = pca_data['layer']\n\n# Extract ALL PCs we'll use (load 10 for flexibility)\nn_pcs_total = 10\npcs_all, variance_all = extract_pc_components(pca_data, n_components=n_pcs_total)\n\nprint(f\"\u2713 Loaded PCA data from layer {pca_layer}\")\nprint(f\"  Extracted {n_pcs_total} PCs\")\nprint(f\"  Variance explained by first 5 PCs: {variance_all[:5]}\")\n\n# Build test vectors: ALL PCs + random baseline\ntest_vecs_full = OrderedDict()\n\n# Add all PCs (positive and negative)\nfor pc_idx in range(n_pcs_total):\n    pc_name = f\"PC{pc_idx+1}\"\n    test_vecs_full[pc_name] = normalize_vector(pcs_all[pc_idx])\n    test_vecs_full[f\"-{pc_name}\"] = normalize_vector(-pcs_all[pc_idx].float())\n\n# Add random baseline vectors\ntorch.manual_seed(42)\nn_random = 20\nfor i in range(n_random):\n    rand_vec = torch.randn(config.hidden_size, dtype=torch.float32)\n    test_vecs_full[f\"Random{i+1}\"] = normalize_vector(rand_vec)\n\nvec_names_full = list(test_vecs_full.keys())\nvecs_tensor_full = torch.stack([test_vecs_full[name] for name in vec_names_full])\n\nprint(f\"\\n\u2713 Prepared {len(vec_names_full)} vectors:\")\nprint(f\"  {n_pcs_total*2} PCs (positive + negative)\")\nprint(f\"  {n_random} random baseline vectors\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# CONFIGURATION: Set analysis parameters here\n# ============================================================================\n\n# Which layers to compute attention patterns for\n# ALL layers: 0-45 (46 total)\nanalysis_layers = list(range(config.num_hidden_layers))\n\n# Which layers to use for averaging in PC comparison plots\n# Middle layers where instruction tuning is most active\ncomparison_layers = list(range(17, 28))  # Layers 17-27\n\n# Which PCs to visualize in layer-wise plots\nplot_pcs = [\"PC1\", \"PC2\", \"PC3\"]\n# plot_pcs = [\"PC1\"]  # Uncomment to focus on PC1 only\n\n# How many PCs to include in PC number comparison\nn_pcs_compare = 10\n\nprint(f\"\ud83d\udccb Analysis Configuration:\")\nprint(f\"  Computing attention for {len(analysis_layers)} layers (all)\")\nprint(f\"  Averaging over layers {comparison_layers[0]}-{comparison_layers[-1]} for PC comparison\")\nprint(f\"  Visualizing {len(plot_pcs)} PCs in layer-wise plots: {plot_pcs}\")\nprint(f\"  Comparing {n_pcs_compare} PCs in PC number analysis\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-compute-intro",
   "metadata": {},
   "source": "## 2. Compute QK and VO Patterns for All Layers\n\nCompute attention patterns once for all PCs and all layers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compute-all",
   "metadata": {},
   "outputs": [],
   "source": "# Compute QK affinity and VO decomposition for all layers\nprint(f\"Computing QK and VO for {len(analysis_layers)} layers...\")\n\nn_vecs_full = len(vec_names_full)\nqk_base_full = np.zeros((len(analysis_layers), n_vecs_full, n_vecs_full))\nqk_inst_full = np.zeros((len(analysis_layers), n_vecs_full, n_vecs_full))\nvo_base_full = np.zeros((len(analysis_layers), n_vecs_full, n_vecs_full))\nvo_inst_full = np.zeros((len(analysis_layers), n_vecs_full, n_vecs_full))\n\nwith torch.inference_mode():\n    for i, layer_idx in enumerate(tqdm(analysis_layers, desc=\"Computing attention patterns\")):\n        # QK affinity\n        qk_b = compute_qk_affinity_matrix(vecs_tensor_full, layer_idx, base_model)\n        qk_i = compute_qk_affinity_matrix(vecs_tensor_full, layer_idx, instruct_model)\n        qk_base_full[i] = qk_b.cpu().numpy()\n        qk_inst_full[i] = qk_i.cpu().numpy()\n        \n        # VO decomposition\n        vo_b = compute_vo_decomposition(vecs_tensor_full, vecs_tensor_full, layer_idx, base_model)\n        vo_i = compute_vo_decomposition(vecs_tensor_full, vecs_tensor_full, layer_idx, instruct_model)\n        vo_base_full[i] = vo_b.cpu().numpy()\n        vo_inst_full[i] = vo_i.cpu().numpy()\n\nprint(f\"\\n\u2713 Computed QK and VO for {len(analysis_layers)} layers\")\nprint(f\"  Arrays shape: {qk_base_full.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compute-zscores",
   "metadata": {},
   "outputs": [],
   "source": "# Compute z-scores using random baseline\nrandom_indices_full = [vec_names_full.index(n) for n in vec_names_full if \"Random\" in n]\n\nprint(\"Computing random baselines for base and instruct models...\")\n\n# Base model random baseline\nqk_random_base = []\nvo_random_base = []\nfor rand_idx in random_indices_full:\n    qk_random_base.append(qk_base_full[:, rand_idx, rand_idx])\n    vo_random_base.append(vo_base_full[:, rand_idx, rand_idx])\nqk_random_base = np.array(qk_random_base)\nvo_random_base = np.array(vo_random_base)\nqk_base_mean = qk_random_base.mean(axis=0)\nqk_base_std = qk_random_base.std(axis=0)\nvo_base_mean = vo_random_base.mean(axis=0)\nvo_base_std = vo_random_base.std(axis=0)\n\n# Instruct model random baseline\nqk_random_inst = []\nvo_random_inst = []\nfor rand_idx in random_indices_full:\n    qk_random_inst.append(qk_inst_full[:, rand_idx, rand_idx])\n    vo_random_inst.append(vo_inst_full[:, rand_idx, rand_idx])\nqk_random_inst = np.array(qk_random_inst)\nvo_random_inst = np.array(vo_random_inst)\nqk_inst_mean = qk_random_inst.mean(axis=0)\nqk_inst_std = qk_random_inst.std(axis=0)\nvo_inst_mean = vo_random_inst.mean(axis=0)\nvo_inst_std = vo_random_inst.std(axis=0)\n\n# Extract PC patterns and convert to z-scores\nqk_zscores_base = {}\nqk_zscores_inst = {}\nvo_zscores_base = {}\nvo_zscores_inst = {}\n\nfor pc_idx in range(n_pcs_total):\n    pc_name = f\"PC{pc_idx+1}\"\n    pc_neg_name = f\"-{pc_name}\"\n    \n    pc_pos_idx = vec_names_full.index(pc_name)\n    pc_neg_idx = vec_names_full.index(pc_neg_name)\n    \n    # Positive PC patterns\n    qk_zscores_base[pc_name] = {\n        \"self\": (qk_base_full[:, pc_pos_idx, pc_pos_idx] - qk_base_mean) / (qk_base_std + 1e-8),\n        \"opposite\": (qk_base_full[:, pc_pos_idx, pc_neg_idx] - qk_base_mean) / (qk_base_std + 1e-8)\n    }\n    qk_zscores_inst[pc_name] = {\n        \"self\": (qk_inst_full[:, pc_pos_idx, pc_pos_idx] - qk_inst_mean) / (qk_inst_std + 1e-8),\n        \"opposite\": (qk_inst_full[:, pc_pos_idx, pc_neg_idx] - qk_inst_mean) / (qk_inst_std + 1e-8)\n    }\n    vo_zscores_base[pc_name] = {\n        \"self\": (vo_base_full[:, pc_pos_idx, pc_pos_idx] - vo_base_mean) / (vo_base_std + 1e-8),\n        \"opposite\": (vo_base_full[:, pc_pos_idx, pc_neg_idx] - vo_base_mean) / (vo_base_std + 1e-8)\n    }\n    vo_zscores_inst[pc_name] = {\n        \"self\": (vo_inst_full[:, pc_pos_idx, pc_pos_idx] - vo_inst_mean) / (vo_inst_std + 1e-8),\n        \"opposite\": (vo_inst_full[:, pc_pos_idx, pc_neg_idx] - vo_inst_mean) / (vo_inst_std + 1e-8)\n    }\n\nprint(f\"\u2713 Computed z-scores for {n_pcs_total} PCs\")\nprint(f\"  Each model normalized by {len(random_indices_full)} random vectors\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-viz-intro",
   "metadata": {},
   "source": "## 3. Layer-wise PC Attention Patterns\n\nVisualize how PCs attend to themselves and their opposites across layers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compute-deltas",
   "metadata": {},
   "outputs": [],
   "source": "# Compute deltas (Instruct - Base) for configured PCs\nqk_delta_zscores = {}\nvo_delta_zscores = {}\n\nfor pc in plot_pcs:\n    qk_delta_zscores[pc] = {\n        \"self\": qk_zscores_inst[pc][\"self\"] - qk_zscores_base[pc][\"self\"],\n        \"opposite\": qk_zscores_inst[pc][\"opposite\"] - qk_zscores_base[pc][\"opposite\"]\n    }\n    vo_delta_zscores[pc] = {\n        \"self\": vo_zscores_inst[pc][\"self\"] - vo_zscores_base[pc][\"self\"],\n        \"opposite\": vo_zscores_inst[pc][\"opposite\"] - vo_zscores_base[pc][\"opposite\"]\n    }\n\nprint(f\"\u2713 Computed deltas for {len(plot_pcs)} PCs: {plot_pcs}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-viz-base-instruct",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize base vs instruct attention patterns\nfig, axes = plt.subplots(2, len(plot_pcs), figsize=(20, 10))\n\n# QK Affinity plots (top row)\nfor i, pc in enumerate(plot_pcs):\n    if len(plot_pcs) == 1:\n        ax = axes[0]\n    else:\n        ax = axes[0, i]\n    \n    # Plot base model\n    ax.plot(analysis_layers, qk_zscores_base[pc][\"self\"], \"o-\", \n            label=f\"Base: {pc}\u2192{pc}\", linewidth=2, alpha=0.7, color=\"C0\")\n    ax.plot(analysis_layers, qk_zscores_base[pc][\"opposite\"], \"s--\", \n            label=f\"Base: {pc}\u2192-{pc}\", linewidth=1.5, alpha=0.7, color=\"C0\")\n    \n    # Plot instruct model\n    ax.plot(analysis_layers, qk_zscores_inst[pc][\"self\"], \"o-\", \n            label=f\"Instruct: {pc}\u2192{pc}\", linewidth=2, alpha=0.7, color=\"C1\")\n    ax.plot(analysis_layers, qk_zscores_inst[pc][\"opposite\"], \"s--\", \n            label=f\"Instruct: {pc}\u2192-{pc}\", linewidth=1.5, alpha=0.7, color=\"C1\")\n    \n    ax.axhline(0, color=\"gray\", linestyle=\":\", alpha=0.5)\n    ax.axvline(pca_layer, color=\"red\", linestyle=\":\", alpha=0.3, label=f\"PCA layer ({pca_layer})\")\n    ax.set_xlabel(\"Layer\", fontsize=11)\n    ax.set_ylabel(\"Z-score (vs random)\", fontsize=11)\n    ax.set_title(f\"QK Affinity: {pc} (Base vs Instruct)\", fontsize=12, fontweight=\"bold\")\n    ax.legend(fontsize=9, loc=\"best\")\n    ax.grid(True, alpha=0.3)\n\n# VO Decomposition plots (bottom row)\nfor i, pc in enumerate(plot_pcs):\n    if len(plot_pcs) == 1:\n        ax = axes[1]\n    else:\n        ax = axes[1, i]\n    \n    # Plot base model\n    ax.plot(analysis_layers, vo_zscores_base[pc][\"self\"], \"o-\", \n            label=f\"Base: {pc} self-bias\", linewidth=2, alpha=0.7, color=\"C0\")\n    ax.plot(analysis_layers, vo_zscores_base[pc][\"opposite\"], \"s--\", \n            label=f\"Base: {pc} opp-bias\", linewidth=1.5, alpha=0.7, color=\"C0\")\n    \n    # Plot instruct model\n    ax.plot(analysis_layers, vo_zscores_inst[pc][\"self\"], \"o-\", \n            label=f\"Instruct: {pc} self-bias\", linewidth=2, alpha=0.7, color=\"C1\")\n    ax.plot(analysis_layers, vo_zscores_inst[pc][\"opposite\"], \"s--\", \n            label=f\"Instruct: {pc} opp-bias\", linewidth=1.5, alpha=0.7, color=\"C1\")\n    \n    ax.axhline(0, color=\"gray\", linestyle=\":\", alpha=0.5)\n    ax.axvline(pca_layer, color=\"red\", linestyle=\":\", alpha=0.3, label=f\"PCA layer ({pca_layer})\")\n    ax.set_xlabel(\"Layer\", fontsize=11)\n    ax.set_ylabel(\"Z-score (vs random)\", fontsize=11)\n    ax.set_title(f\"VO Decomposition: {pc} (Base vs Instruct)\", fontsize=12, fontweight=\"bold\")\n    ax.legend(fontsize=9, loc=\"best\")\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-viz-delta",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize instruction tuning effects (delta)\nfig, axes = plt.subplots(2, len(plot_pcs), figsize=(20, 10))\n\n# QK Affinity deltas (top row)\nfor i, pc in enumerate(plot_pcs):\n    if len(plot_pcs) == 1:\n        ax = axes[0]\n    else:\n        ax = axes[0, i]\n    \n    ax.plot(analysis_layers, qk_delta_zscores[pc][\"self\"], \"o-\", \n            label=f\"{pc}\u2192{pc} (self)\", linewidth=2.5, color=\"C2\")\n    ax.plot(analysis_layers, qk_delta_zscores[pc][\"opposite\"], \"s-\", \n            label=f\"{pc}\u2192-{pc} (opposite)\", linewidth=2.5, color=\"C3\")\n    \n    ax.axhline(0, color=\"black\", linestyle=\"-\", alpha=0.5, linewidth=1)\n    ax.fill_between(analysis_layers, 0, qk_delta_zscores[pc][\"self\"], \n                    alpha=0.2, color=\"C2\")\n    ax.fill_between(analysis_layers, 0, qk_delta_zscores[pc][\"opposite\"], \n                    alpha=0.2, color=\"C3\")\n    \n    ax.set_xlabel(\"Layer\", fontsize=11)\n    ax.set_ylabel(\"\u0394 Z-score (Instruct - Base)\", fontsize=11)\n    ax.set_title(f\"Instruction Tuning Effect: {pc} QK\", fontsize=12, fontweight=\"bold\")\n    ax.legend(fontsize=10)\n    ax.grid(True, alpha=0.3)\n\n# VO Decomposition deltas (bottom row)\nfor i, pc in enumerate(plot_pcs):\n    if len(plot_pcs) == 1:\n        ax = axes[1]\n    else:\n        ax = axes[1, i]\n    \n    ax.plot(analysis_layers, vo_delta_zscores[pc][\"self\"], \"o-\", \n            label=f\"{pc} self-bias\", linewidth=2.5, color=\"C2\")\n    ax.plot(analysis_layers, vo_delta_zscores[pc][\"opposite\"], \"s-\", \n            label=f\"{pc} opposite-bias\", linewidth=2.5, color=\"C3\")\n    \n    ax.axhline(0, color=\"black\", linestyle=\"-\", alpha=0.5, linewidth=1)\n    ax.fill_between(analysis_layers, 0, vo_delta_zscores[pc][\"self\"], \n                    alpha=0.2, color=\"C2\")\n    ax.fill_between(analysis_layers, 0, vo_delta_zscores[pc][\"opposite\"], \n                    alpha=0.2, color=\"C3\")\n    \n    ax.set_xlabel(\"Layer\", fontsize=11)\n    ax.set_ylabel(\"\u0394 Z-score (Instruct - Base)\", fontsize=11)\n    ax.set_title(f\"Instruction Tuning Effect: {pc} VO\", fontsize=12, fontweight=\"bold\")\n    ax.legend(fontsize=10)\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-pc-comparison-intro",
   "metadata": {},
   "source": "## 4. PC Number Comparison\n\nCompare instruction tuning effects across PC numbers to see if PC1 is special."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pc-comparison",
   "metadata": {},
   "outputs": [],
   "source": "# Compute PC comparison using configured layers and PCs\nprint(f\"Analyzing instruction tuning effects for PC1-PC{n_pcs_compare}...\")\nprint(f\"  Averaging over layers {comparison_layers[0]}-{comparison_layers[-1]}\")\n\n# Map layer indices to comparison_layers\nlayer_mask = np.array([layer_idx in comparison_layers for layer_idx in analysis_layers])\ncomparison_layer_indices = np.where(layer_mask)[0]\n\nprint(f\"  Using layer indices: {comparison_layer_indices}\")\n\n# Compute effects for each PC\npc_effects = []\nfor pc_idx in range(n_pcs_compare):\n    pc_name = f\"PC{pc_idx+1}\"\n    pc_neg_name = f\"-{pc_name}\"\n    \n    pc_pos_idx = vec_names_full.index(pc_name)\n    pc_neg_idx = vec_names_full.index(pc_neg_name)\n    \n    # Get patterns for comparison layers only\n    qk_base_self = (qk_base_full[comparison_layer_indices, pc_pos_idx, pc_pos_idx] - qk_base_mean[comparison_layer_indices]) / (qk_base_std[comparison_layer_indices] + 1e-8)\n    qk_inst_self = (qk_inst_full[comparison_layer_indices, pc_pos_idx, pc_pos_idx] - qk_inst_mean[comparison_layer_indices]) / (qk_inst_std[comparison_layer_indices] + 1e-8)\n    qk_delta_self = qk_inst_self - qk_base_self\n    \n    qk_base_opp = (qk_base_full[comparison_layer_indices, pc_pos_idx, pc_neg_idx] - qk_base_mean[comparison_layer_indices]) / (qk_base_std[comparison_layer_indices] + 1e-8)\n    qk_inst_opp = (qk_inst_full[comparison_layer_indices, pc_pos_idx, pc_neg_idx] - qk_inst_mean[comparison_layer_indices]) / (qk_inst_std[comparison_layer_indices] + 1e-8)\n    qk_delta_opp = qk_inst_opp - qk_base_opp\n    \n    vo_base_self = (vo_base_full[comparison_layer_indices, pc_pos_idx, pc_pos_idx] - vo_base_mean[comparison_layer_indices]) / (vo_base_std[comparison_layer_indices] + 1e-8)\n    vo_inst_self = (vo_inst_full[comparison_layer_indices, pc_pos_idx, pc_pos_idx] - vo_inst_mean[comparison_layer_indices]) / (vo_inst_std[comparison_layer_indices] + 1e-8)\n    vo_delta_self = vo_inst_self - vo_base_self\n    \n    vo_base_opp = (vo_base_full[comparison_layer_indices, pc_pos_idx, pc_neg_idx] - vo_base_mean[comparison_layer_indices]) / (vo_base_std[comparison_layer_indices] + 1e-8)\n    vo_inst_opp = (vo_inst_full[comparison_layer_indices, pc_pos_idx, pc_neg_idx] - vo_inst_mean[comparison_layer_indices]) / (vo_inst_std[comparison_layer_indices] + 1e-8)\n    vo_delta_opp = vo_inst_opp - vo_base_opp\n    \n    # Take mean absolute delta across comparison layers\n    pc_effects.append({\n        'pc_num': pc_idx + 1,\n        'variance_explained': float(variance_all[pc_idx]),\n        'qk_self': np.mean(np.abs(qk_delta_self)),\n        'qk_opposite': np.mean(np.abs(qk_delta_opp)),\n        'vo_self': np.mean(np.abs(vo_delta_self)),\n        'vo_opposite': np.mean(np.abs(vo_delta_opp)),\n    })\n\nprint(f\"\u2713 Computed mean effects across {len(comparison_layer_indices)} layers\")\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\npc_nums = [d['pc_num'] for d in pc_effects]\nqk_self = [d['qk_self'] for d in pc_effects]\nqk_opp = [d['qk_opposite'] for d in pc_effects]\nvo_self = [d['vo_self'] for d in pc_effects]\nvo_opp = [d['vo_opposite'] for d in pc_effects]\n\n# QK plot\nax = axes[0]\nax.plot(pc_nums, qk_self, 'o-', label='Self-attention', linewidth=2.5, markersize=8, color='C2')\nax.plot(pc_nums, qk_opp, 's-', label='Opposite-attention', linewidth=2.5, markersize=8, color='C3')\nax.set_xlabel('PC Number', fontsize=12)\nax.set_ylabel(f'Mean |\u0394 Z-score| (layers {comparison_layers[0]}-{comparison_layers[-1]})', fontsize=12)\nax.set_title('QK Affinity: Instruction Tuning Effect by PC', fontsize=13, fontweight='bold')\nax.legend(fontsize=11)\nax.grid(True, alpha=0.3)\nax.set_xticks(pc_nums)\n\n# VO plot\nax = axes[1]\nax.plot(pc_nums, vo_self, 'o-', label='Self-bias', linewidth=2.5, markersize=8, color='C2')\nax.plot(pc_nums, vo_opp, 's-', label='Opposite-bias', linewidth=2.5, markersize=8, color='C3')\nax.set_xlabel('PC Number', fontsize=12)\nax.set_ylabel(f'Mean |\u0394 Z-score| (layers {comparison_layers[0]}-{comparison_layers[-1]})', fontsize=12)\nax.set_title('VO Decomposition: Instruction Tuning Effect by PC', fontsize=13, fontweight='bold')\nax.legend(fontsize=11)\nax.grid(True, alpha=0.3)\nax.set_xticks(pc_nums)\n\nplt.tight_layout()\nplt.show()\n\n# Print summary\nprint(f\"\\n\ud83d\udcca Instruction Tuning Effects by PC (mean |\u0394 Z-score| over layers {comparison_layers[0]}-{comparison_layers[-1]}):\")\nprint(f\"\\n{'PC':<5} {'Var%':<8} {'QK Self':<10} {'QK Opp':<10} {'VO Self':<10} {'VO Opp':<10}\")\nprint(\"=\" * 65)\nfor d in pc_effects:\n    print(f\"PC{d['pc_num']:<3} {d['variance_explained']*100:>6.2f}%  \"\n          f\"{d['qk_self']:>8.3f}\u03c3  {d['qk_opposite']:>8.3f}\u03c3  \"\n          f\"{d['vo_self']:>8.3f}\u03c3  {d['vo_opposite']:>8.3f}\u03c3\")\n\nprint(f\"\\n\ud83c\udfaf Key Finding:\")\nmax_qk = max(pc_effects, key=lambda x: x['qk_self'])\nmax_vo = max(pc_effects, key=lambda x: x['vo_self'])\nprint(f\"  Strongest QK self-attention effect: PC{max_qk['pc_num']} ({max_qk['qk_self']:.3f}\u03c3)\")\nprint(f\"  Strongest VO self-bias effect: PC{max_vo['pc_num']} ({max_vo['vo_self']:.3f}\u03c3)\")\nif max_qk['pc_num'] == 1 and max_vo['pc_num'] == 1:\n    print(f\"  \u2713 PC1 (dominant variance) also shows strongest instruction tuning effects!\")\nelse:\n    print(f\"  \u2717 Instruction tuning effects do NOT align with variance ranking\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": "## 5. Summary\n\nThis analysis reveals how instruction tuning modifies attention routing in the persona subspace:\n\n- **Layer-wise patterns**: Shows how PC attention changes across all layers\n- **Base vs Instruct**: Compares attention patterns between base and instruction-tuned models\n- **PC sensitivity**: Determines whether PC1 (dominant variance component) is also most affected by instruction tuning\n- **Configurable**: Easy to adjust layers and PCs via config cell\n\n**Key Insights:**\n- QK affinity reveals which semantic directions attend to each other\n- VO decomposition shows what semantic content flows through attention\n- Instruction tuning modifies these patterns, potentially aligning them with task objectives"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}