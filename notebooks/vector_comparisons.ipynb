{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"/workspace/steering_vectors_trained_activation.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9be4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b193dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"steering_vector\"] = df[\"steering_vector\"].apply(lambda x: np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d74bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trained = df[df[\"trained_or_activation\"]]\n",
    "df_activation = df[~df[\"trained_or_activation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eba9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Ensure both DataFrames are sorted by dataset for alignment\n",
    "df_trained_sorted = df_trained.sort_values(\"dataset\").reset_index(drop=True)\n",
    "df_activation_sorted = df_activation.sort_values(\"dataset\").reset_index(drop=True)\n",
    "\n",
    "# Sanity check: datasets should match\n",
    "assert all(df_trained_sorted[\"dataset\"].values == df_activation_sorted[\"dataset\"].values), \"Datasets do not align!\"\n",
    "\n",
    "trained_vectors = np.stack(df_trained_sorted[\"steering_vector\"].values)\n",
    "activation_vectors = np.stack(df_activation_sorted[\"steering_vector\"].values)\n",
    "\n",
    "# Compute cosine similarity for each pair\n",
    "cos_sims = np.array([\n",
    "    cosine_similarity(trained_vec.reshape(1, -1), activation_vec.reshape(1, -1))[0, 0]\n",
    "    for trained_vec, activation_vec in zip(trained_vectors, activation_vectors)\n",
    "])\n",
    "\n",
    "# Add to DataFrame for inspection\n",
    "df_similarity = pd.DataFrame({\n",
    "    \"dataset\": df_trained_sorted[\"dataset\"].values,\n",
    "    \"cosine_similarity\": cos_sims\n",
    "})\n",
    "\n",
    "df_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61949d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# histogram of cosine similarity\n",
    "plt.hist(cos_sims, bins=20, edgecolor='black')\n",
    "plt.title(\"Histogram of Cosine Similarity\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of vector magnitudes\n",
    "plt.hist(np.linalg.norm(trained_vectors, axis=1), bins=20, edgecolor='black')\n",
    "plt.title(\"Histogram of Vector Magnitude\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29116615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of activation vector magnitudes\n",
    "plt.hist(np.linalg.norm(activation_vectors, axis=1), bins=20, edgecolor='black')\n",
    "plt.title(\"Histogram of Activation Vector Magnitude\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c093eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Compute norms\n",
    "trained_norms = np.linalg.norm(trained_vectors, axis=1)\n",
    "activation_norms = np.linalg.norm(activation_vectors, axis=1)\n",
    "\n",
    "# Pearson correlation\n",
    "pearson_corr, pearson_p = pearsonr(trained_norms, activation_norms)\n",
    "print(f\"Pearson correlation between vector norms: r={pearson_corr:.4f}, p={pearson_p:.4g}\")\n",
    "\n",
    "# Spearman correlation\n",
    "spearman_corr, spearman_p = spearmanr(trained_norms, activation_norms)\n",
    "print(f\"Spearman correlation between vector norms: r={spearman_corr:.4f}, p={spearman_p:.4g}\")\n",
    "\n",
    "# Optionally, scatter plot\n",
    "plt.scatter(trained_norms, activation_norms, alpha=0.6)\n",
    "plt.xlabel(\"Trained Vector Norm\")\n",
    "plt.ylabel(\"Activation Vector Norm\")\n",
    "plt.title(\"Scatter Plot of Vector Norms\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "PERSONA_ROOT = Path(\"/workspace/persona-data\")\n",
    "def load_activation_vector(dataset: str, target_layer: int) -> Optional[torch.Tensor]:\n",
    "    if \"__trait__\" in dataset:\n",
    "        model_prefix = dataset.split(\"__trait__\", 1)[0]\n",
    "        trait = dataset.split(\"__trait__\", 1)[1]\n",
    "        vec_file = PERSONA_ROOT / f\"{model_prefix}/traits_240/vectors/{trait}.pt\"\n",
    "        if not vec_file.exists():\n",
    "            return None\n",
    "        data: Dict[str, torch.Tensor] = torch.load(vec_file, map_location=\"cpu\")\n",
    "        vec = data[\"pos_neg_50\"][target_layer]\n",
    "        return vec.float()\n",
    "    if \"__role__\" in dataset:\n",
    "        model_prefix = \"qwen-3-32b\"  # use Qwen activation vectors for roles\n",
    "        role = dataset.split(\"__role__\", 1)[1]\n",
    "        vec_file = PERSONA_ROOT / f\"{model_prefix}/roles_240/vectors/{role}.pt\"\n",
    "        if not vec_file.exists():\n",
    "            return None\n",
    "        data: Dict[str, torch.Tensor] = torch.load(vec_file, map_location=\"cpu\")\n",
    "        vec_pos = data[\"pos_3\"][target_layer]\n",
    "        vec_default = data[\"default_1\"][target_layer]\n",
    "        vec_contrast = vec_pos - vec_default\n",
    "        return vec_contrast.float()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14363999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load activation vectors for all datasets for all layers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_all_activation_vectors(datasets, num_layers=64):\n",
    "    \"\"\"\n",
    "    Load activation vectors for all datasets for all layers.\n",
    "\n",
    "    Args:\n",
    "        datasets (list[str]): List of dataset names.\n",
    "        num_layers (int): Number of layers to load (default: 32).\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[int, torch.Tensor]]: \n",
    "            Mapping from dataset name to {layer_idx: activation_vector}.\n",
    "    \"\"\"\n",
    "    all_vectors = {}\n",
    "    for dataset in tqdm(datasets):\n",
    "        layer_vectors = {}\n",
    "        for layer_idx in range(num_layers):\n",
    "            vec = load_activation_vector(dataset, layer_idx)\n",
    "            if vec is not None:\n",
    "                layer_vectors[layer_idx] = vec\n",
    "        all_vectors[dataset] = layer_vectors\n",
    "    return all_vectors\n",
    "\n",
    "# Example usage:\n",
    "all_activation_vectors = load_all_activation_vectors(df[\"dataset\"].unique(), num_layers=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(len(all_activation_vectors[dataset]) for dataset in all_activation_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "# compare trained vector to corresponding activation vector\n",
    "datasets_in_order = df[\"dataset\"].unique()\n",
    "cosine_sims_by_layer = []\n",
    "for layer in trange(32):\n",
    "    cosine_sims = {}\n",
    "    for dataset in datasets_in_order:\n",
    "        trained_vector = df_trained[df_trained[\"dataset\"] == dataset][\"steering_vector\"].values[0]\n",
    "        activation_vector = all_activation_vectors[dataset][layer]\n",
    "        cosine_sim = cosine_similarity(\n",
    "            trained_vector.reshape(1, -1), activation_vector.reshape(1, -1)\n",
    "        )[0, 0]\n",
    "        cosine_sims[dataset] = cosine_sim\n",
    "    cosine_sims_by_layer.append(cosine_sims)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3633702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute mean cosine similarity per layer\n",
    "mean_cosine_sims = [np.mean(list(layer_dict.values())) for layer_dict in cosine_sims_by_layer]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.axvline(x=22, color='red', linestyle='--', label='Trained Layer (22)')\n",
    "plt.legend()\n",
    "plt.plot(range(32), mean_cosine_sims, marker='o')\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Mean Cosine Similarity\")\n",
    "plt.title(\"Mean Cosine Similarity between Trained and Activation Vectors vs Layer\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cea75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Choose the layer N to compare with layer 32 (Python index 31)\n",
    "layer_n = 22  # You can change this to any layer index you want\n",
    "\n",
    "datasets_in_order = df[\"dataset\"].unique()\n",
    "cosine_sims_n_vs_32 = []\n",
    "\n",
    "for dataset in datasets_in_order:\n",
    "    vec_n = all_activation_vectors[dataset][layer_n]\n",
    "    vec_32 = all_activation_vectors[dataset][31]\n",
    "    sim = cosine_similarity(\n",
    "        vec_n.reshape(1, -1), vec_32.reshape(1, -1)\n",
    "    )[0, 0]\n",
    "    cosine_sims_n_vs_32.append(sim)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(cosine_sims_n_vs_32, bins=30, color='skyblue', edgecolor='k')\n",
    "plt.xlabel(f\"Cosine Similarity (Layer {layer_n} vs Layer 32)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"Cosine Similarity between Activation Vectors @ Layer {layer_n} and @ Layer 32\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ec300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For each layer, compute the mean cosine similarity between that layer's activation vector and layer 32's activation vector, averaged over all datasets\n",
    "num_layers = 32\n",
    "mean_cosine_sims_vs_32 = []\n",
    "\n",
    "for layer_idx in range(num_layers):\n",
    "    sims = []\n",
    "    for dataset in datasets_in_order:\n",
    "        vec_n = all_activation_vectors[dataset][layer_idx]\n",
    "        vec_32 = all_activation_vectors[dataset][31]\n",
    "        sim = cosine_similarity(\n",
    "            vec_n.reshape(1, -1), vec_32.reshape(1, -1)\n",
    "        )[0, 0]\n",
    "        sims.append(sim)\n",
    "    mean_cosine_sims_vs_32.append(np.mean(sims))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_layers + 1), mean_cosine_sims_vs_32, marker='o')\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Mean Cosine Similarity to Layer 32\")\n",
    "plt.title(\"Mean Cosine Similarity: Activation Vector @ Layer N vs Layer 32 (Averaged Over Datasets)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c46fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# For layer 22, get the full similarity matrix between activation vectors and trained vectors\n",
    "datasets_in_order = df[\"dataset\"].unique()\n",
    "trained_vectors = np.stack([\n",
    "    df_trained[df_trained[\"dataset\"] == dataset][\"steering_vector\"].values[0]\n",
    "    for dataset in datasets_in_order\n",
    "])\n",
    "activation_vectors = np.stack([\n",
    "    all_activation_vectors[dataset][22]\n",
    "    for dataset in datasets_in_order\n",
    "])\n",
    "\n",
    "sim_matrix = cosine_similarity(activation_vectors, trained_vectors)\n",
    "\n",
    "sim_df = pd.DataFrame(\n",
    "    sim_matrix,\n",
    "    index=[f\"{ds} (activation)\" for ds in datasets_in_order],\n",
    "    columns=[f\"{ds} (trained)\" for ds in datasets_in_order]\n",
    ")\n",
    "\n",
    "\n",
    "# Flatten the similarity matrix to get all pairwise similarities\n",
    "all_sims = sim_matrix.flatten()\n",
    "\n",
    "# Plot the CDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "sorted_sims = np.sort(all_sims)\n",
    "cdf = np.arange(1, len(sorted_sims) + 1) / len(sorted_sims)\n",
    "plt.plot(sorted_sims, cdf, label=\"CDF of Cosine Similarities\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Cumulative Probability\")\n",
    "plt.title(\"CDF of Cosine Similarities (Activation vs Trained, Layer 22)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdfcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_var = np.var(trained_vectors, axis=-1)\n",
    "activation_var = np.var(activation_vectors, axis=-1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(trained_var, activation_var, alpha=0.6)\n",
    "plt.xlabel(\"Trained Vector Variance\")\n",
    "plt.ylabel(\"Activation Vector Variance\")\n",
    "plt.title(\"Variance of Trained and Activation Vectors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf39e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_mean = np.mean(trained_vectors, axis=-1)\n",
    "activation_mean = np.mean(activation_vectors, axis=-1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(trained_mean, activation_mean, alpha=0.6)\n",
    "plt.xlabel(\"Trained Vector Mean\")\n",
    "plt.ylabel(\"Activation Vector Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3dd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c669843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
